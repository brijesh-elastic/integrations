config_version: 2
interval: {{interval}}
resource.tracer:
  enabled: {{enable_request_tracer}}
  filename: "../../logs/cel/http-request-trace-*.ndjson"
  maxbackups: 5
{{#if proxy_url}}
resource.proxy_url: {{proxy_url}}
{{/if}}
{{#if ssl}}
resource.ssl: {{ssl}}
{{/if}}
{{#if http_client_timeout}}
resource.timeout: {{http_client_timeout}}
{{/if}}
resource.url: {{url}}
state:
  api_key: {{api_key}}
  batch_size: {{batch_size}}
redact:
  fields:
    - api_key
program: |
  (
    state.?want_more.orValue(false) ?
      state.interval_time
    :
      now
  ).as(interval_time,
     has(state.assets) && (state.is_all_assets_fetched || !state.?is_current_vulnerabilities_fetched.orValue(false)) ?
      {
        "assets": state.assets,
        "is_all_assets_fetched": state.is_all_assets_fetched,
        "asset_vuln_ids": state.asset_vuln_ids,
        "interval_time": interval_time,
        ?"next_asset_cursor": state.?next_asset_cursor,
      }
    :
      request(
        "POST",
        state.url.trim_right("/") + "/vm/v4/integration/assets?" + {
          "size": [string(state.batch_size)],
          "includeUniqueIdentifiers": ["true"],
          ?"includeSame": has(state.?cursor.last_interval_time) ? optional.none() : optional.of(["true"]),
          ?"comparisonTime": state.?cursor.last_interval_time.optMap(v, [v]),
          ?"cursor": state.?next_asset_cursor.optMap(v, [v]),
        }.format_query()
      ).with({
        "Header": {
          "X-Api-Key": [state.api_key]
        }
      }).do_request().as(resp, resp.StatusCode == 200 ?
        resp.Body.decode_json().as(body, {
          "events": [{"message": "retry"}],
          "batch_size": state.batch_size,
          "api_key": state.api_key,
          ?"next_asset_cursor": has(body.?metadata.cursor) && body.metadata.cursor != null ? optional.of(body.metadata.cursor) : optional.none(),
          "is_all_assets_fetched": has(body.metadata.cursor) && body.metadata.cursor != null ? false : true,
          "assets": body.data,
          "asset_vuln_ids": body.data.map(a, 
            a.?same.orValue([]).map(s, s.vulnerability_id) + a.?new.orValue([]).map(n, n.vulnerability_id) + a.?remediated.orValue([]).map(r, r.vulnerability_id)
          ).flatten().as(vuln_ids, 
            vuln_ids.map(vuln_id, string(vuln_id)).as(str_vuln_ids, zip(str_vuln_ids, vuln_ids))
          ).keys(),
          "interval_time": interval_time,
          "want_more": true
        })
      :
        {
          "events": {
            "error": {
              "code": string(resp.StatusCode),
              "id": string(resp.Status),
              "message": "POST " + state.url.trim_right("/") + "/vm/v4/integration/assets:" + (
                size(resp.Body) != 0 ?
                  string(resp.Body)
                :
                  string(resp.Status) + ' (' + string(resp.StatusCode) + ')'
              ),
            },
          },
          "want_more": false,
          "api_key": state.api_key,
          "batch_size": state.batch_size
        }
      )
  ).as(work,
    has(work.events) ? work : // Exit early
      (
        (has(state.vulnerabilities) && state.is_current_vulnerabilities_fetched) ?
          work.with({
            "vulnerabilities": state.vulnerabilities,
            "is_current_vulnerabilities_fetched": state.is_current_vulnerabilities_fetched
          })
        :
          request(
            "POST",
            state.url.trim_right("/") + "/vm/v4/integration/vulnerabilities?" + {
              "size": ["500"],
              ?"cursor": state.?next_vuln_cursor.optMap(v, [v]),
            }.format_query()
          ).with({
            "Header": {
              "X-Api-Key": [state.api_key],
              "Content-Type": ["application/json"]
            },
            "Body": {
              "vulnerability": work.asset_vuln_ids.as(x, sprintf("id IN ['%s']", [x.join("','")])),
            }.encode_json(),
          }).do_request().as(resp, resp.StatusCode == 200 ?
            resp.Body.decode_json().as(body, {
              "events": [{"message": "retry"}],
              "batch_size": state.batch_size,
              "api_key": state.api_key,
              "assets": state.assets,
              "is_all_assets_fetched": state.is_all_assets_fetched,
              ?"next_vuln_cursor": has(body.?metadata.cursor) && body.metadata.cursor != null ? optional.of(body.metadata.cursor) : optional.none(),
              ?"next_asset_cursor": work.?next_asset_cursor,
              "is_current_vulnerabilities_fetched": has(body.metadata.cursor) && body.metadata.cursor != null ? false : true,
              "vulnerabilities": (state.?vulnerabilities.orValue([]) + body.data).flatten(),
              "asset_vuln_ids": work.asset_vuln_ids,
              "interval_time": work.interval_time,
              "want_more": true
            })
          :
            {
              "events": {
                "error": {
                  "code": string(resp.StatusCode),
                  "id": string(resp.Status),
                  "message": "POST " + state.url.trim_right("/") + "/vm/v4/integration/vulnerabilities:" + (
                    size(resp.Body) != 0 ?
                      string(resp.Body)
                    :
                      string(resp.Status) + ' (' + string(resp.StatusCode) + ')'
                  ),
                },
              },
              "want_more": false,
              "api_key": state.api_key,
              "batch_size": state.batch_size
            }
          )
      )
  ).as(work,
    (type(work.events) == map || !(work.is_all_assets_fetched || work.?is_current_vulnerabilities_fetched.orValue(false))) ? 
      work // Error or more vulnerabilities to fetch for current assets.
    :
      work.is_all_assets_fetched ? 
        // All assets fetched. Save cursor and end iteration.
        {
          "events": [],
          "cursor": {
            ?"last_interval_time": optional.of(work.interval_time),
          },
          "want_more": false,
          "api_key": state.api_key,
          "batch_size": state.batch_size,
        }
      : 
        // All vulnerabilities of current assets batch are fetched. Publish events.
        work.with({
          // convert vulnerabilities to map for better searching
          "vulnerabilities": work.vulnerabilities.map(e, {
            "key": e.id,
            "value": e
          }).as(result, zip(
            result.map(e, e.key),
            result.map(e, e.value)
          )),
          // combine same[] new[] remediated[] into vulnerability[]
          "assets": work.assets.map(e, e.with({
            "vulnerabilities": e.?same.orValue([]) + e.?new.orValue([]) + e.?remediated.orValue([]).map(r, r.with({"remediated": true})),
          }).drop(["new","remediated","same"]))
        }).as(work, {
          "events": work.assets.map(e, e.vulnerabilities.map(v, {
            "message": e.with({"vulnerability": v.with(
              work.?vulnerabilities[v.vulnerability_id].orValue("not present") != "not present" ?
                work.vulnerabilities[v.vulnerability_id]
              :
                {"is_enriched": false}
            )}).drop("vulnerabilities").encode_json()
          })).flatten(),
          "is_all_assets_fetched": work.is_all_assets_fetched,
          "is_current_vulnerabilities_fetched": work.is_current_vulnerabilities_fetched,
          ?"next_asset_cursor": work.?next_asset_cursor,
          "interval_time": work.interval_time,
          //"cursor": {
          //  ?"last_interval_time": work.is_all_assets_fetched ? optional.of(state.interval_time) : optional.none(),
          //},
          "want_more": !(work.is_all_assets_fetched && work.is_current_vulnerabilities_fetched),
          "api_key": state.api_key,
          "batch_size": state.batch_size,
        })
  )
tags:
{{#if preserve_original_event}}
  - preserve_original_event
{{/if}}
{{#if preserve_duplicate_custom_fields}}
  - preserve_duplicate_custom_fields
{{/if}}
{{#each tags as |tag|}}
  - {{tag}}
{{/each}}
{{#contains "forwarded" tags}}
publisher_pipeline.disable_host: true
{{/contains}}
processors:
- drop_event:
    when:
      equals:
        message: retry
{{#if processors}}
{{processors}}
{{/if}}
